{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"\ud83d\ude87 Collective Crossing","text":"<p>A multi-agent reinforcement learning environment for simulating collective behavior in tram boarding/exiting scenarios. This project provides a grid-world environment where multiple agents interact to achieve their goals while sharing some resources together.</p>"},{"location":"#overview","title":"\ud83c\udfaf Overview","text":"<p>The <code>CollectiveCrossingEnv</code> simulates a minimal tram boarding scenario where coordination is essential to find the optimal collective behavior:</p> <ul> <li>Boarding agents start in the platform area and navigate to the tram door</li> <li>Exiting agents start inside the tram and navigate to the exit</li> <li>Simple collision avoidance prevents agents from occupying the same space, which makes the passing through the tram door a bottleneck and a challenge</li> <li>Configurable geometry allows customization of tram size, door position, and environment</li> <li>Flexible reward system supports multiple reward strategies (default, simple distance, binary)</li> <li>Customizable termination configurable episode termination conditions</li> <li>Adaptive truncation flexible episode truncation policies</li> </ul>"},{"location":"#quick-start","title":"\ud83d\ude80 Quick Start","text":"<pre><code>from collectivecrossing import CollectiveCrossingEnv\nfrom collectivecrossing.configs import CollectiveCrossingConfig\nfrom collectivecrossing.reward_configs import DefaultRewardConfig\nfrom collectivecrossing.terminated_configs import AllAtDestinationTerminatedConfig\nfrom collectivecrossing.truncated_configs import MaxStepsTruncatedConfig\nfrom collectivecrossing.observation_configs import DefaultObservationConfig\n\n# Create environment with configurable systems\nreward_config = DefaultRewardConfig(\n    boarding_destination_reward=15.0,\n    tram_door_reward=10.0,\n    tram_area_reward=5.0,\n    distance_penalty_factor=0.1\n)\n\nterminated_config = AllAtDestinationTerminatedConfig()\ntruncated_config = MaxStepsTruncatedConfig(max_steps=100)\nobservation_config = DefaultObservationConfig()\n\nconfig = CollectiveCrossingConfig(\n    width=12, height=8, division_y=4,\n    tram_door_left=5, tram_door_right=6, tram_length=10,\n    num_boarding_agents=5, num_exiting_agents=3,\n    render_mode=\"rgb_array\",\n    reward_config=reward_config,\n    terminated_config=terminated_config,\n    truncated_config=truncated_config,\n    observation_config=observation_config\n)\n\nenv = CollectiveCrossingEnv(config=config)\nobservations, infos = env.reset(seed=42)\n</code></pre>"},{"location":"#key-features","title":"\ud83c\udfae Key Features","text":"<ul> <li>Multi-agent simulation with boarding and exiting agents</li> <li>Collision avoidance prevents agents from overlapping</li> <li>Configurable geometry customizable tram and door positions</li> <li>Ray RLlib compatible uses MultiAgentEnv API</li> <li>Multiple rendering modes ASCII and RGB visualization</li> <li>Type-safe configuration using Pydantic v2</li> <li>Flexible reward system multiple reward strategies with custom configurations</li> <li>Customizable termination configurable episode ending conditions</li> <li>Adaptive truncation flexible episode timeout policies</li> <li>Configurable observations customizable observation functions and spaces</li> </ul>"},{"location":"#documentation","title":"\ud83d\udcda Documentation","text":"<p>\ud83c\udf10 Live Documentation - Complete documentation site</p> <ul> <li>Installation Guide - Detailed setup instructions</li> <li>Usage Guide - Complete usage examples and configuration</li> <li>Baselines - Baseline policies and demo scripts</li> <li>Development Guide - Testing, contributing, and development</li> <li>Features Overview - Comprehensive feature descriptions</li> <li>Local Deployment - Simple deployment guide</li> </ul>"},{"location":"#installation","title":"\ud83d\udee0\ufe0f Installation","text":"<pre><code># Clone and install\ngit clone https://github.com/nima-siboni/collectivecrossing.git\ncd collectivecrossing\nuv sync\n</code></pre> <p>See Installation Guide for detailed instructions.</p>"},{"location":"#quick-deploy","title":"\ud83d\ude80 Quick Deploy","text":"<pre><code># Deploy documentation to GitHub Pages\n./scripts/docs.sh deploy\n</code></pre> <p>See Local Deployment Guide for details.</p>"},{"location":"#testing","title":"\ud83e\uddea Testing","text":"<pre><code># Run tests\nuv run pytest\n\n# Run with coverage\nuv run pytest --cov=collectivecrossing\n</code></pre>"},{"location":"#contributing","title":"\ud83e\udd1d Contributing","text":"<ol> <li>Fork the repository</li> <li>Create a feature branch</li> <li>Make your changes</li> <li>Run tests</li> <li>Submit a pull request</li> </ol> <p>See Development Guide for detailed contribution guidelines.</p>"},{"location":"#license","title":"\ud83d\udcc4 License","text":"<p>This project is licensed under the Apache License 2.0.</p> <p>Happy simulating! \ud83d\ude87\u2728</p>"},{"location":"baselines/","title":"Baseline Policies","text":"<p>This document describes the baseline policies available in the Collective Crossing environment. These policies provide simple reference implementations for comparison with more sophisticated multi-agent reinforcement learning approaches.</p>"},{"location":"baselines/#available-policies","title":"Available Policies","text":""},{"location":"baselines/#greedy-policy","title":"Greedy Policy","text":"<p>The Greedy Policy (<code>GreedyPolicy</code>) implements a simple greedy approach where agents move directly toward their destinations without considering other agents:</p> <ul> <li>Boarding agents: Move directly toward the tram door, then to their destination</li> <li>Exiting agents: Move directly toward the tram door, then to their destination  </li> <li>Behavior: Agents don't coordinate and move as directly as possible</li> <li>Randomness: Supports epsilon-greedy exploration with configurable randomness factor</li> </ul> <p> </p>"},{"location":"baselines/#waiting-policy","title":"Waiting Policy","text":"<p>The Waiting Policy (<code>WaitingPolicy</code>) implements a coordinated approach that separates exit and entry phases:</p> <ul> <li>Phase 1: Boarding agents wait until all exiting agents have completed their journey</li> <li>Phase 2: Once waiting period ends, agents use greedy movement toward destinations</li> <li>Coordination: Creates clear separation between exit and entry phases</li> <li>Randomness: Supports epsilon-greedy exploration with configurable randomness factor</li> </ul> <p> </p>"},{"location":"baselines/#running-baseline-policies","title":"Running Baseline Policies","text":""},{"location":"baselines/#demo-scripts","title":"Demo Scripts","text":"<p>Two demo scripts are available to run and visualize the baseline policies:</p>"},{"location":"baselines/#greedy-policy-demo","title":"Greedy Policy Demo","text":"<pre><code>python scripts/run_greedy_policy_demo.py\n</code></pre> <p>Features: - Runs greedy policy with configurable epsilon (randomness factor) - Generates animated visualization showing agent movement - Collects and displays performance statistics - Saves animation as GIF file</p>"},{"location":"baselines/#waiting-policy-demo","title":"Waiting Policy Demo","text":"<pre><code>python scripts/run_waiting_policy_demo.py\n</code></pre> <p>Features: - Runs waiting policy with configurable epsilon (randomness factor) - Generates animated visualization showing coordinated movement - Collects and displays performance statistics - Saves animation as GIF file</p>"},{"location":"baselines/#configuration","title":"Configuration","text":"<p>Both scripts use the same environment configuration: - Grid size: 15\u00d78 with tram door at positions 4-7 - Agents: 5 boarding agents, 10 exiting agents - Termination: Individual destination-based termination - Truncation: Maximum 200 steps - Reward: Constant negative step penalty (-1.0)</p>"},{"location":"baselines/#customization","title":"Customization","text":"<p>You can modify the scripts to: - Adjust environment parameters (grid size, number of agents, etc.) - Change epsilon values for exploration - Modify reward configurations - Customize visualization settings</p>"},{"location":"baselines/#usage-in-code","title":"Usage in Code","text":"<pre><code>from baseline_policies import create_greedy_policy, create_waiting_policy\n\n# Create policies\ngreedy_policy = create_greedy_policy(epsilon=0.1)\nwaiting_policy = create_waiting_policy(epsilon=0.1)\n\n# Use in environment loop\nfor agent_id, observation in observations.items():\n    action = policy.get_action(agent_id, observation, env)\n    # Apply action...\n</code></pre>"},{"location":"baselines/#performance-comparison","title":"Performance Comparison","text":"<p>These baseline policies serve as reference points for evaluating more sophisticated approaches:</p> <ul> <li>Greedy Policy: Fast but may cause congestion at bottlenecks</li> <li>Waiting Policy: Slower but avoids conflicts through coordination</li> </ul> <p>Use these baselines to establish performance benchmarks when developing and testing new multi-agent reinforcement learning algorithms.</p>"},{"location":"development/","title":"Development Guide","text":""},{"location":"development/#testing","title":"Testing","text":""},{"location":"development/#running-tests","title":"Running Tests","text":"<pre><code># Run all tests\nuv run pytest\n\n# Run specific test files\nuv run pytest tests/collectivecrossing/envs/test_collective_crossing.py\n\n# Run with coverage\nuv run pytest --cov=collectivecrossing\n\n# Run with verbose output\nuv run pytest -v\n\n# Run tests in parallel\nuv run pytest -n auto\n</code></pre>"},{"location":"development/#test-structure","title":"Test Structure","text":"<pre><code>tests/\n\u251c\u2500\u2500 collectivecrossing/\n\u2502   \u2514\u2500\u2500 envs/\n\u2502       \u251c\u2500\u2500 test_collective_crossing.py    # Main environment tests\n\u2502       \u251c\u2500\u2500 test_action_agent_validity.py  # Action validation tests\n\u2502       \u251c\u2500\u2500 test_dummy.py                  # Dummy environment tests\n\u2502       \u251c\u2500\u2500 test_rewards.py                # Reward function tests\n\u2502       \u251c\u2500\u2500 test_terminateds.py            # Termination function tests\n\u2502       \u251c\u2500\u2500 test_truncateds.py             # Truncation function tests\n\u2502       \u2514\u2500\u2500 test_trajectory_vcr.py         # Trajectory tests\n\u2514\u2500\u2500 fixtures/\n    \u2514\u2500\u2500 trajectories/\n        \u251c\u2500\u2500 current/                       # Current test data\n        \u2514\u2500\u2500 golden/                        # Golden test data\n</code></pre>"},{"location":"development/#writing-tests","title":"Writing Tests","text":"<pre><code>import pytest\nfrom collectivecrossing import CollectiveCrossingEnv\nfrom collectivecrossing.configs import CollectiveCrossingConfig\nfrom collectivecrossing.reward_configs import DefaultRewardConfig\nfrom collectivecrossing.terminated_configs import AllAtDestinationTerminatedConfig\nfrom collectivecrossing.truncated_configs import MaxStepsTruncatedConfig\nfrom collectivecrossing.observation_configs import DefaultObservationConfig\n\ndef test_basic_environment():\n    # Create configuration with configurable systems\n    reward_config = DefaultRewardConfig(\n        boarding_destination_reward=15.0,\n        tram_door_reward=10.0,\n        tram_area_reward=5.0,\n        distance_penalty_factor=0.1\n    )\n\n    terminated_config = AllAtDestinationTerminatedConfig()\n    truncated_config = MaxStepsTruncatedConfig(max_steps=50)\n    observation_config = DefaultObservationConfig()\n\n    config = CollectiveCrossingConfig(\n        width=10, height=8, division_y=4,\n        tram_door_x=5, tram_door_width=2, tram_length=8,\n        num_boarding_agents=3, num_exiting_agents=2,\n        reward_config=reward_config,\n        terminated_config=terminated_config,\n        truncated_config=truncated_config,\n        observation_config=observation_config\n    )\n\n    env = CollectiveCrossingEnv(config=config)\n    observations, infos = env.reset(seed=42)\n\n    assert len(observations) == 5  # 3 boarding + 2 exiting agents\n    assert not env.terminated\n    assert not env.truncated\n</code></pre>"},{"location":"development/#testing-new-features","title":"Testing New Features","text":""},{"location":"development/#testing-reward-functions","title":"Testing Reward Functions","text":"<pre><code>from collectivecrossing.rewards import DefaultRewardFunction\nfrom collectivecrossing.reward_configs import DefaultRewardConfig\n\ndef test_default_reward_function():\n    config = DefaultRewardConfig(\n        boarding_destination_reward=15.0,\n        tram_door_reward=10.0,\n        tram_area_reward=5.0,\n        distance_penalty_factor=0.1\n    )\n\n    reward_func = DefaultRewardFunction(config)\n    # Test reward computation\n    reward = reward_func.compute_reward(agent_state, action, next_state)\n    assert isinstance(reward, float)\n</code></pre>"},{"location":"development/#testing-termination-functions","title":"Testing Termination Functions","text":"<pre><code>from collectivecrossing.terminateds import AllAtDestinationTerminatedFunction\nfrom collectivecrossing.terminated_configs import AllAtDestinationTerminatedConfig\n\ndef test_all_at_destination_termination():\n    config = AllAtDestinationTerminatedConfig()\n    terminated_func = AllAtDestinationTerminatedFunction(config)\n\n    # Test termination logic\n    terminated = terminated_func.check_termination(agent_states, episode_info)\n    assert isinstance(terminated, bool)\n</code></pre>"},{"location":"development/#testing-truncation-functions","title":"Testing Truncation Functions","text":"<pre><code>from collectivecrossing.truncateds import MaxStepsTruncatedFunction\nfrom collectivecrossing.truncated_configs import MaxStepsTruncatedConfig\n\ndef test_max_steps_truncation():\n    config = MaxStepsTruncatedConfig(max_steps=100)\n    truncated_func = MaxStepsTruncatedFunction(config)\n\n    # Test truncation logic\n    truncated = truncated_func.calculate_truncated(agent_id, env)\n    assert isinstance(truncated, bool)\n</code></pre>"},{"location":"development/#testing-observation-functions","title":"Testing Observation Functions","text":"<pre><code>from collectivecrossing.observations import DefaultObservationFunction\nfrom collectivecrossing.observation_configs import DefaultObservationConfig\n\ndef test_default_observation_function():\n    config = DefaultObservationConfig()\n    observation_func = DefaultObservationFunction(config)\n\n    # Test observation generation\n    observation = observation_func.get_agent_observation(agent_id, env)\n    assert isinstance(observation, np.ndarray)\n    assert observation.dtype == np.int32\n</code></pre>"},{"location":"development/#trajectory-testing","title":"Trajectory Testing","text":"<p>The project includes comprehensive trajectory testing to ensure environment behavior consistency:</p> <pre><code># Run trajectory tests\nuv run pytest tests/collectivecrossing/envs/test_trajectory_vcr.py\n\n# Update golden trajectories (if needed)\nuv run pytest tests/collectivecrossing/envs/test_trajectory_vcr.py --update-golden\n</code></pre>"},{"location":"development/#code-quality-tools","title":"Code Quality Tools","text":"<p>This project uses modern development tools:</p> <ul> <li>\ud83e\udd80 Ruff - Fast Python linter and formatter</li> <li>\ud83d\udd12 Pre-commit - Automated code quality checks</li> <li>\ud83d\udccb Pytest - Testing framework</li> <li>\ud83d\udd0d Coverage - Code coverage reporting</li> <li>\ud83d\udd0d MyPy - Static type checking</li> </ul>"},{"location":"development/#running-code-quality-tools","title":"Running Code Quality Tools","text":"<pre><code># Pre-commit hooks (run automatically on commit)\ngit add .\ngit commit -m \"Your commit message\"\n\n# Manual linting\nuv run ruff check . --config tool-config.toml\n\n# Manual formatting\nuv run ruff format . --config tool-config.toml\n\n# Run pre-commit manually\nuv run pre-commit run --all-files\n\n# Type checking\nuv run mypy src/collectivecrossing/\n</code></pre>"},{"location":"development/#pre-commit-configuration","title":"Pre-commit Configuration","text":"<p>The project uses pre-commit hooks to ensure code quality:</p> <pre><code># .pre-commit-config.yaml\nrepos:\n  - repo: https://github.com/astral-sh/ruff-pre-commit\n    rev: v0.1.6\n    hooks:\n      - id: ruff\n        args: [--fix]\n      - id: ruff-format\n</code></pre>"},{"location":"development/#project-structure","title":"Project Structure","text":"<pre><code>collectivecrossing/\n\u251c\u2500\u2500 \ud83d\udcc1 src/collectivecrossing/\n\u2502   \u251c\u2500\u2500 \ud83c\udfae collectivecrossing.py      # Main environment implementation\n\u2502   \u251c\u2500\u2500 \u2699\ufe0f configs.py                 # Configuration classes with validation\n\u2502   \u251c\u2500\u2500 \ud83c\udfaf actions.py                 # Action definitions and mappings\n\u2502   \u251c\u2500\u2500 \ud83c\udff7\ufe0f types.py                   # Type definitions (AgentType, etc.)\n\u2502   \u251c\u2500\u2500 \ud83c\udf81 reward_configs.py          # Reward function configurations\n\u2502   \u251c\u2500\u2500 \ud83c\udf81 rewards.py                 # Reward function implementations\n\u2502   \u251c\u2500\u2500 \u23f9\ufe0f terminated_configs.py      # Termination function configurations\n\u2502   \u251c\u2500\u2500 \u23f9\ufe0f terminateds.py             # Termination function implementations\n\u2502   \u251c\u2500\u2500 \u23f1\ufe0f truncated_configs.py       # Truncation function configurations\n\u2502   \u251c\u2500\u2500 \u23f1\ufe0f truncateds.py              # Truncation function implementations\n\u2502   \u251c\u2500\u2500 \ud83d\udcc1 utils/\n\u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcd0 geometry.py            # Geometry utilities (TramBoundaries)\n\u2502   \u2502   \u2514\u2500\u2500 \ud83d\udd27 pydantic.py            # Pydantic configuration utilities\n\u2502   \u2514\u2500\u2500 \ud83d\udcc1 tests/                     # Environment-specific tests\n\u251c\u2500\u2500 \ud83d\udcc1 tests/                         # Main test suite\n\u251c\u2500\u2500 \ud83d\udcc1 examples/                      # Usage examples\n\u251c\u2500\u2500 \u2699\ufe0f pyproject.toml                 # Project configuration\n\u251c\u2500\u2500 \ud83d\udd27 tool-config.toml               # Development tools configuration\n\u2514\u2500\u2500 \ud83d\udccb uv.lock                        # Dependency lock file\n</code></pre>"},{"location":"development/#adding-dependencies","title":"Adding Dependencies","text":"<pre><code># Add main dependency\nuv add package-name\n\n# Add development dependency\nuv add --dev package-name\n\n# Add dependency with specific version\nuv add \"package-name&gt;=1.0.0,&lt;2.0.0\"\n\n# Remove dependency\nuv remove package-name\n</code></pre>"},{"location":"development/#building-and-publishing","title":"Building and Publishing","text":"<pre><code># Build the package\nuv run build\n\n# Check the built package\nuv run twine check dist/*\n\n# Upload to PyPI (if you have access)\nuv run twine upload dist/*\n</code></pre>"},{"location":"development/#contributing","title":"Contributing","text":""},{"location":"development/#development-workflow","title":"Development Workflow","text":"<ol> <li>Fork the repository \ud83c\udf74</li> <li>Create a feature branch \ud83c\udf3f    <code>bash    git checkout -b feature/your-feature-name</code></li> <li>Make your changes \u270f\ufe0f</li> <li>Run tests \ud83e\uddea    <code>bash    uv run pytest    uv run ruff check . --config tool-config.toml</code></li> <li>Commit your changes \ud83d\udcbe    <code>bash    git add .    git commit -m \"Add your feature description\"</code></li> <li>Push to your fork \ud83d\udce4    <code>bash    git push origin feature/your-feature-name</code></li> <li>Submit a pull request \ud83d\udd04</li> </ol>"},{"location":"development/#code-style-guidelines","title":"Code Style Guidelines","text":"<ul> <li>Follow PEP 8 style guidelines</li> <li>Use type hints for all function parameters and return values</li> <li>Write docstrings for all public functions and classes</li> <li>Keep functions small and focused</li> <li>Use meaningful variable and function names</li> </ul>"},{"location":"development/#commit-message-format","title":"Commit Message Format","text":"<p>Use conventional commit messages:</p> <pre><code>feat: add new reward function configuration\nfix: resolve termination logic bug\ndocs: update usage examples\ntest: add tests for truncation functions\nrefactor: improve configuration validation\n</code></pre>"},{"location":"development/#adding-new-features","title":"Adding New Features","text":"<p>When adding new features, follow these guidelines:</p> <ol> <li>Configuration First - Add configuration classes for new features</li> <li>Type Safety - Use Pydantic for configuration validation</li> <li>Testing - Write comprehensive tests for new functionality</li> <li>Documentation - Update documentation with examples</li> <li>Backward Compatibility - Maintain compatibility with existing APIs</li> </ol>"},{"location":"development/#adding-new-reward-functions","title":"Adding New Reward Functions","text":"<pre><code># 1. Create reward configuration\nclass CustomRewardConfig(RewardConfig):\n    custom_parameter: float = Field(default=1.0, description=\"Custom parameter\")\n\n# 2. Create reward function\nclass CustomRewardFunction:\n    def __init__(self, config: CustomRewardConfig):\n        self.config = config\n\n    def compute_reward(self, agent_state, action, next_state):\n        # Implement reward logic\n        return reward_value\n\n# 3. Add to registry\nREWARD_CONFIGS[\"custom\"] = CustomRewardConfig\nREWARD_FUNCTIONS[\"custom\"] = CustomRewardFunction\n</code></pre>"},{"location":"development/#adding-new-termination-functions","title":"Adding New Termination Functions","text":"<pre><code># 1. Create termination configuration\nclass CustomTerminatedConfig(TerminatedConfig):\n    custom_parameter: bool = Field(default=True, description=\"Custom parameter\")\n\n# 2. Create termination function\nclass CustomTerminatedFunction:\n    def __init__(self, config: CustomTerminatedConfig):\n        self.config = config\n\n    def check_termination(self, agent_states, episode_info):\n        # Implement termination logic\n        return terminated\n\n# 3. Add to registry\nTERMINATED_CONFIGS[\"custom\"] = CustomTerminatedConfig\nTERMINATED_FUNCTIONS[\"custom\"] = CustomTerminatedFunction\n</code></pre>"},{"location":"development/#adding-new-truncation-functions","title":"Adding New Truncation Functions","text":"<pre><code># 1. Create truncation configuration\nclass CustomTruncatedConfig(TruncatedConfig):\n    custom_parameter: int = Field(default=100, description=\"Custom parameter\")\n\n# 2. Create truncation function\nclass CustomTruncatedFunction:\n    def __init__(self, config: CustomTruncatedConfig):\n        self.config = config\n\n    def check_truncation(self, step_count, episode_info):\n        # Implement truncation logic\n        return truncated\n\n# 3. Add to registry\nTRUNCATED_CONFIGS[\"custom\"] = CustomTruncatedConfig\nTRUNCATED_FUNCTIONS[\"custom\"] = CustomTruncatedFunction\n</code></pre>"},{"location":"development/#troubleshooting","title":"Troubleshooting","text":""},{"location":"development/#common-issues","title":"Common Issues","text":"<ol> <li>Test failures - Check if golden trajectories need updating</li> <li>Configuration errors - Verify Pydantic validation rules</li> <li>Import errors - Ensure all dependencies are installed</li> <li>Type checking errors - Add proper type hints</li> </ol>"},{"location":"development/#getting-help","title":"Getting Help","text":"<ul> <li>Check existing issues on GitHub</li> <li>Create a new issue with detailed error information</li> <li>Include your Python version and operating system</li> <li>Provide minimal reproduction examples</li> </ul>"},{"location":"features/","title":"Features Overview","text":""},{"location":"features/#environment-features","title":"\ud83d\ude87 Environment Features","text":""},{"location":"features/#multi-agent-simulation","title":"Multi-Agent Simulation","text":"<ul> <li>Boarding agents \ud83d\udeb6\u200d\u2642\ufe0f start in the platform area and navigate to the tram door</li> <li>Exiting agents \ud83d\udeb6\u200d\u2640\ufe0f start inside the tram and navigate to the exit</li> <li>Dynamic agent management with configurable agent counts</li> <li>Individual agent tracking with unique identifiers</li> </ul>"},{"location":"features/#basic-collision-handling","title":"Basic Collision Handling","text":"<ul> <li>\ud83d\udee1\ufe0f Same-cell prevention only agents are not allowed to occupy the same grid cell</li> <li>No yielding/coordination agents do not respect each other explicitly; they can bump and block</li> </ul>"},{"location":"features/#configurable-geometry","title":"Configurable Geometry","text":"<ul> <li>\ud83c\udfd7\ufe0f Customizable tram size adjustable width, length, and position</li> <li>Flexible door positioning configurable door location and width</li> <li>Environment scaling variable grid dimensions</li> <li>Division line customization tram/waiting area boundary</li> </ul>"},{"location":"features/#ray-rllib-compatibility","title":"Ray RLlib Compatibility","text":"<ul> <li>\ud83d\ude80 MultiAgentEnv API compatible with Ray RLlib interfaces used in examples/tests</li> <li>Standard gym interface follows OpenAI Gym conventions</li> <li>Action space support discrete action spaces for all agents</li> <li>Observation space structured observations for each agent</li> </ul>"},{"location":"features/#rendering-modes","title":"Rendering Modes","text":"<ul> <li>\ud83c\udfa8 RGB visualization grid-based rendering for images</li> <li>ASCII rendering text-based visualization for terminals</li> <li>Simple coloring different colors for different agent types</li> <li>Step-by-step updates render after environment steps</li> </ul>"},{"location":"features/#reward-system-features","title":"\ud83c\udf81 Reward System Features","text":""},{"location":"features/#flexible-reward-strategies","title":"Flexible Reward Strategies","text":"<ul> <li>Default, simple distance, binary, and custom strategies</li> <li>Configured via <code>RewardConfig</code> classes; parameters depend on the chosen strategy</li> </ul>"},{"location":"features/#termination-system-features","title":"\u23f9\ufe0f Termination System Features","text":""},{"location":"features/#configurable-termination-conditions","title":"Configurable Termination Conditions","text":"<ul> <li>All at destination, individual at destination, and custom policies</li> <li>Set via <code>TerminatedConfig</code> classes; keep it simple or extend as needed</li> </ul>"},{"location":"features/#truncation-system-features","title":"\u23f1\ufe0f Truncation System Features","text":""},{"location":"features/#flexible-truncation-policies","title":"Flexible Truncation Policies","text":"<ul> <li>Max steps and custom truncation policies</li> <li>Controlled via <code>TruncatedConfig</code> classes</li> </ul>"},{"location":"features/#observation-system-features","title":"\ud83d\udc41\ufe0f Observation System Features","text":""},{"location":"features/#configurable-observation-functions","title":"Configurable Observation Functions","text":"<ul> <li>Agent positions each agent observes its own and other agents' positions</li> <li>Tram door information door boundaries and division line</li> <li>Environment geometry grid dimensions and tram parameters</li> <li>Gym-style spaces observation spaces provided per-agent</li> <li>Custom strategies can be implemented via new observation configs/functions</li> </ul>"},{"location":"features/#configuration-features","title":"\u2699\ufe0f Configuration Features","text":""},{"location":"features/#type-safe-configuration","title":"Type-Safe Configuration","text":"<ul> <li>\ud83d\udd12 Pydantic v2 integration runtime validation of configuration data</li> <li>Automatic validation errors raised at model construction time</li> <li>Immutable configurations frozen after creation</li> <li>IDE support full autocomplete and type hints</li> </ul>"},{"location":"features/#comprehensive-validation","title":"Comprehensive Validation","text":"<ul> <li>Tram parameter validation ensures logical tram dimensions</li> <li>Boundary checking validates all coordinates within grid</li> <li>Agent count limits reasonable limits for performance</li> <li>Render mode validation ensures valid rendering options</li> <li>Parameter validation validates reward, termination, truncation, and observation parameters</li> </ul>"},{"location":"features/#clear-error-messages","title":"Clear Error Messages","text":"<ul> <li>\ud83d\udcac Descriptive validation failures helpful error messages</li> <li>Context-aware errors specific to the validation failure</li> <li>Debugging support detailed error information</li> <li>User-friendly messages easy to understand and fix</li> </ul>"},{"location":"features/#flexible-configuration","title":"Flexible Configuration","text":"<ul> <li>Default values sensible defaults for common use cases</li> <li>Optional parameters only specify what you need</li> <li>Configuration inheritance extend existing configurations</li> <li>Environment-specific configs different configs for different scenarios</li> <li>Modular configuration separate configs for rewards, termination, truncation, observations</li> </ul>"},{"location":"features/#rllib-integration","title":"RLlib Integration","text":"<ul> <li>See the RLlib compatibility guide: RLlib MultiAgentEnv Compatibility</li> </ul>"},{"location":"features/#architecture-features","title":"\ud83c\udfd7\ufe0f Architecture Features","text":""},{"location":"features/#modular-design","title":"Modular Design","text":"<ul> <li>\ud83e\udde9 Separated concerns distinct modules for different functionality</li> <li>Clean interfaces well-defined public APIs</li> <li>Loose coupling minimal dependencies between modules</li> <li>Extensible design easy to add new features</li> </ul>"},{"location":"features/#private-encapsulation","title":"Private Encapsulation","text":"<ul> <li>\ud83d\udd10 Proper encapsulation private members where appropriate</li> <li>Public properties clean external interfaces</li> <li>Internal state management controlled access to internal data</li> <li>API stability stable public interfaces</li> </ul>"},{"location":"features/#environment-extensions","title":"Environment Extensions","text":"<ul> <li>\ud83c\udf81 Extensible configuration system modify environment behavior</li> <li>Custom functions implement custom reward, termination, truncation, and observation logic</li> </ul>"},{"location":"features/#performance-considerations","title":"Performance Considerations","text":"<ul> <li>Reasonable execution speed suitable for small to medium grid sizes</li> <li>Straightforward Python clarity prioritized over micro-optimizations</li> <li>No heavy vectorization simple loops over agents and grid</li> </ul>"},{"location":"features/#key-capabilities","title":"\ud83c\udfaf Key Capabilities","text":""},{"location":"features/#training-support","title":"Training Support","text":"<ul> <li>Episode management proper episode termination and truncation</li> <li>Step counting track episode progress</li> <li>Seed management reproducible environments</li> <li>Flexible systems multiple reward, termination, truncation, and observation strategies</li> </ul>"},{"location":"features/#system-architecture","title":"System Architecture","text":"<p>All systems (Reward, Termination, Truncation, Observation) feature: - Type-safe configurations \ud83d\udd12 Pydantic-based configs - Automatic validation \u2705 parameter validation and bounds checking - Extensible design \ud83d\udd27 easy to add new strategies - Performance optimized \u26a1 efficient computation and checking</p>"},{"location":"installation/","title":"Installation Guide","text":""},{"location":"installation/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.10+ \ud83d\udc0d</li> <li>uv package manager \u26a1</li> </ul>"},{"location":"installation/#installation-steps","title":"Installation Steps","text":""},{"location":"installation/#1-clone-the-repository","title":"1. Clone the Repository","text":"<pre><code>git clone &lt;repository-url&gt;\ncd collectivecrossing\n</code></pre>"},{"location":"installation/#2-install-dependencies","title":"2. Install Dependencies","text":"<pre><code># Install main dependencies\nuv sync\n\n# Install development dependencies\nuv sync --dev\n</code></pre>"},{"location":"installation/#optional-demo-training-dependencies","title":"Optional: Demo / Training Dependencies","text":"<p>The core package does not require RL training libraries. To run the RLlib demo and training examples, install the optional <code>demo</code> group (includes <code>ray[rllib]</code> and <code>torch</code>):</p> <pre><code>uv sync --group demo\n</code></pre>"},{"location":"installation/#3-set-up-development-environment","title":"3. Set Up Development Environment","text":"<pre><code># Set up pre-commit hooks\nuv run pre-commit install\n</code></pre>"},{"location":"installation/#4-verify-installation","title":"4. Verify Installation","text":"<pre><code># Run tests to verify everything works\nuv run pytest\n\n# Check code quality\nuv run ruff check . --config tool-config.toml\n\n# Run type checking\nuv run mypy src/collectivecrossing/\n</code></pre>"},{"location":"installation/#alternative-installation-methods","title":"Alternative Installation Methods","text":""},{"location":"installation/#using-pip-not-recommended","title":"Using pip (not recommended)","text":"<pre><code>pip install -e .\n</code></pre>"},{"location":"installation/#using-conda","title":"Using conda","text":"<pre><code>conda create -n collectivecrossing python=3.10\nconda activate collectivecrossing\nuv sync\n</code></pre>"},{"location":"installation/#testing-the-installation","title":"Testing the Installation","text":"<p>After installation, you can test that everything works correctly:</p> <pre><code># Test basic environment creation\nfrom collectivecrossing import CollectiveCrossingEnv\nfrom collectivecrossing.configs import CollectiveCrossingConfig\nfrom collectivecrossing.reward_configs import DefaultRewardConfig\nfrom collectivecrossing.terminated_configs import AllAtDestinationTerminatedConfig\nfrom collectivecrossing.truncated_configs import MaxStepsTruncatedConfig\nfrom collectivecrossing.observation_configs import DefaultObservationConfig\n\n# Create a simple configuration with configurable systems\nreward_config = DefaultRewardConfig(\n    boarding_destination_reward=15.0,\n    tram_door_reward=10.0,\n    tram_area_reward=5.0,\n    distance_penalty_factor=0.1\n)\n\nterminated_config = AllAtDestinationTerminatedConfig()\ntruncated_config = MaxStepsTruncatedConfig(max_steps=50)\nobservation_config = DefaultObservationConfig()\n\nconfig = CollectiveCrossingConfig(\n    width=10, height=8, division_y=4,\n    tram_door_x=5, tram_door_width=2, tram_length=8,\n    num_boarding_agents=3, num_exiting_agents=2,\n    reward_config=reward_config,\n    terminated_config=terminated_config,\n    truncated_config=truncated_config,\n    observation_config=observation_config\n)\n\n# Create and test environment\nenv = CollectiveCrossingEnv(config=config)\nobservations, infos = env.reset(seed=42)\nprint(f\"Environment created successfully with {len(observations)} agents\")\n</code></pre>"},{"location":"installation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"installation/#common-issues","title":"Common Issues","text":"<ol> <li>uv not found: Install uv from https://docs.astral.sh/uv/</li> <li>Python version: Ensure you have Python 3.10 or higher</li> <li>Permission errors: Use <code>uv sync --user</code> or check your Python environment</li> <li>Import errors: Make sure all dependencies are properly installed</li> <li>Test failures: Run <code>uv run pytest -v</code> for detailed error information</li> </ol>"},{"location":"installation/#getting-help","title":"Getting Help","text":"<p>If you encounter issues during installation, please: 1. Check the GitHub Issues 2. Create a new issue with your error details 3. Include your Python version and operating system 4. Provide the complete error message and stack trace</p>"},{"location":"rllib_multiagent_compatibility/","title":"RLlib MultiAgentEnv Compatibility","text":"<p>This page explains how <code>CollectiveCrossingEnv</code> aligns with Ray RLlib's <code>MultiAgentEnv</code> API and how to plug it into RLlib training.</p> <p>Reference: RLlib MultiAgentEnv API.</p>"},{"location":"rllib_multiagent_compatibility/#api-conformance","title":"API Conformance","text":"<p><code>CollectiveCrossingEnv</code> follows RLlib's multi-agent return signatures:</p> <ul> <li>Observations: <code>Dict[AgentID, obs]</code></li> <li>Rewards: <code>Dict[AgentID, float]</code></li> <li>Terminated: <code>Dict[AgentID, bool]</code> with global key \"all\"</li> <li>Truncated: <code>Dict[AgentID, bool]</code> with global key \"all\"</li> <li>Infos: <code>Dict[AgentID, dict]</code></li> </ul> <p>Agent IDs are stable strings like <code>boarding_0</code>, <code>boarding_1</code>, <code>exiting_0</code>. After <code>reset</code>, active agent IDs are available via <code>env.agents</code>.</p>"},{"location":"rllib_multiagent_compatibility/#possible_agents-agents-and-_agents","title":"possible_agents, agents, and _agents","text":"<ul> <li>possible_agents: The superset of agent IDs that can appear for a given configuration (e.g., all boarding/exiting indices). This is static for a fixed config and useful for pre-declaring spaces.</li> <li>agents: The dynamic set of currently active agent IDs. Populated on <code>reset</code> and may shrink as agents terminate. Step/return dicts are keyed by this set. This matches RLlib\u2019s expectation that returns are dictionaries keyed by active agents each step.</li> <li>_agents: Internal storage used by the environment to track active agents. Treat this as private; external code should use <code>agents</code>/<code>possible_agents</code>.</li> </ul> <p>Compatibility note: RLlib does not require <code>possible_agents</code>, but fully supports dynamic agent sets via dict-based returns. The environment\u2019s use of <code>agents</code> for live IDs and the <code>\"__all__\"</code> key in <code>terminated</code>/<code>truncated</code> conforms to the RLlib MultiAgentEnv API.</p> <p>Observation/action spaces are exposed per-agent via helpers like <code>env.get_observation_space(agent_id)</code> and <code>env.get_action_space(agent_id)</code> and are gymnasium-compatible, as expected by RLlib.</p>"},{"location":"rllib_multiagent_compatibility/#reset-and-step","title":"Reset and Step","text":"<ul> <li><code>reset(seed) -&gt; (obs_dict, info_dict)</code> returns initial observations and infos for all agents.</li> <li><code>step(actions_dict) -&gt; (obs, rewards, terminated, truncated, infos)</code> returns per-agent dicts and sets <code>terminated[\"__all__\"]</code>/<code>truncated[\"__all__\"]</code> accordingly, matching RLlib's requirements.</li> </ul> <p>See RLlib docs for the exact dictionary structures: Multi-agent envs.</p>"},{"location":"rllib_multiagent_compatibility/#termination-and-truncation","title":"Termination and Truncation","text":"<ul> <li>Episode termination policies (all agents vs. individual) are configured via <code>TerminatedConfig</code> and surfaced through per-agent flags plus \"all\".</li> <li>Truncation policies (e.g., max steps) are configured via <code>TruncatedConfig</code> and surfaced similarly.</li> </ul> <p>RLlib expects both termination and truncation dictionaries; this environment provides both.</p>"},{"location":"rllib_multiagent_compatibility/#policy-mapping","title":"Policy Mapping","text":"<p>Standard RLlib policy mapping works out-of-the-box. For example, you can map boarding vs. exiting agents to different policies using <code>policy_mapping_fn</code>.</p> <p>For training orchestration details, see RLlib: Running actual training experiments.</p>"},{"location":"rllib_multiagent_compatibility/#minimal-rllib-example","title":"Minimal RLlib Example","text":"<pre><code>from ray.rllib.algorithms.ppo import PPOConfig\nfrom ray.tune.registry import register_env\nfrom collectivecrossing import CollectiveCrossingEnv\nfrom collectivecrossing.configs import CollectiveCrossingConfig\n\n# Register env factory for RLlib\nregister_env(\n    \"collective_crossing\",\n    lambda env_config: CollectiveCrossingEnv(\n        config=CollectiveCrossingConfig(**env_config)\n    ),\n)\n\n# Map boarding vs exiting to different policies (example)\ndef policy_mapping_fn(agent_id, *args, **kwargs):\n    return \"boarding\" if agent_id.startswith(\"boarding_\") else \"exiting\"\n\nalgo = (\n    PPOConfig()\n    .environment(env=\"collective_crossing\", env_config={\n        \"width\": 12,\n        \"height\": 8,\n        \"division_y\": 4,\n        \"tram_door_left\": 5,\n        \"tram_door_right\": 6,\n        \"tram_length\": 10,\n        \"num_boarding_agents\": 5,\n        \"num_exiting_agents\": 3,\n        \"exiting_destination_area_y\": 1,\n        \"boarding_destination_area_y\": 7,\n    })\n    .multi_agent(policy_mapping_fn=policy_mapping_fn)\n    .build()\n)\n</code></pre> <p>For agent grouping, policy modules, and more advanced multi-agent features, consult RLlib's docs: Multi-agent envs.</p>"},{"location":"setup_local_deployment/","title":"Local Deployment Setup","text":"<p>This guide shows you how to deploy your documentation locally without using GitHub Actions.</p>"},{"location":"setup_local_deployment/#quick-setup","title":"\ud83d\ude80 Quick Setup","text":""},{"location":"setup_local_deployment/#1-build-and-deploy-in-one-command","title":"1. Build and Deploy in One Command","text":"<pre><code># Deploy directly to GitHub Pages\n./scripts/docs.sh deploy\n</code></pre> <p>This command will: - Build your documentation - Deploy it to the <code>gh-pages</code> branch - Make it available at <code>https://nima-siboni.github.io/collectivecrossing/</code></p>"},{"location":"setup_local_deployment/#2-manual-steps-if-needed","title":"2. Manual Steps (if needed)","text":"<p>If you prefer to do it step by step:</p> <pre><code># Build the documentation\nuv run mkdocs build\n\n# Deploy to GitHub Pages\nuv run mkdocs gh-deploy\n</code></pre>"},{"location":"setup_local_deployment/#local-development","title":"\ud83d\udee0\ufe0f Local Development","text":""},{"location":"setup_local_deployment/#using-the-documentation-script","title":"Using the Documentation Script","text":"<pre><code># Start local development server\n./scripts/docs.sh serve\n\n# Build documentation\n./scripts/docs.sh build\n\n# Clean build directory\n./scripts/docs.sh clean\n\n# Deploy to GitHub Pages\n./scripts/docs.sh deploy\n</code></pre>"},{"location":"setup_local_deployment/#manual-commands","title":"Manual Commands","text":"<pre><code># Start local server\nuv run mkdocs serve\n\n# Build documentation\nuv run mkdocs build\n\n# Deploy to GitHub Pages\nuv run mkdocs gh-deploy\n</code></pre>"},{"location":"setup_local_deployment/#project-structure","title":"\ud83d\udcc1 Project Structure","text":"<pre><code>collectivecrossing/\n\u251c\u2500\u2500 docs/                          # Documentation source files\n\u2502   \u251c\u2500\u2500 index.md                   # Home page\n\u2502   \u251c\u2500\u2500 installation.md            # Installation guide\n\u2502   \u251c\u2500\u2500 usage.md                   # Usage guide\n\u2502   \u251c\u2500\u2500 development.md             # Development guide\n\u2502   \u251c\u2500\u2500 features.md                # Features overview\n\u2502   \u251c\u2500\u2500 setup_local_deployment.md  # This guide\n\u2502   \u2514\u2500\u2500 assets/                    # Images and other assets\n\u251c\u2500\u2500 mkdocs.yml                     # MkDocs configuration\n\u2514\u2500\u2500 scripts/docs.sh               # Documentation management script\n</code></pre>"},{"location":"setup_local_deployment/#configuration","title":"\u2699\ufe0f Configuration","text":""},{"location":"setup_local_deployment/#mkdocs-configuration-mkdocsyml","title":"MkDocs Configuration (<code>mkdocs.yml</code>)","text":"<p>The configuration uses minimal settings with Material theme defaults:</p> <ul> <li>Material theme with default styling</li> <li>Navigation structure for organized content</li> <li>Search functionality for finding content</li> <li>Responsive design for mobile devices</li> <li>Clean and simple appearance</li> </ul>"},{"location":"setup_local_deployment/#how-it-works","title":"\ud83d\udd27 How It Works","text":"<ol> <li><code>mkdocs build</code> - Creates HTML files in the <code>site/</code> directory</li> <li><code>mkdocs gh-deploy</code> - Pushes the built files to the <code>gh-pages</code> branch</li> <li>GitHub Pages - Serves the files from the <code>gh-pages</code> branch</li> </ol>"},{"location":"setup_local_deployment/#troubleshooting","title":"\ud83d\udea8 Troubleshooting","text":""},{"location":"setup_local_deployment/#common-issues","title":"Common Issues","text":"<ol> <li>Permission errors</li> <li>Make sure you have write access to the repository</li> <li> <p>Check that your Git credentials are set up correctly</p> </li> <li> <p>Build errors</p> </li> <li>Check that all dependencies are installed: <code>uv sync --dev</code></li> <li> <p>Verify your <code>mkdocs.yml</code> configuration</p> </li> <li> <p>Deployment fails</p> </li> <li>Ensure you're on the <code>main</code> branch</li> <li>Check that you have the latest changes committed</li> </ol>"},{"location":"setup_local_deployment/#getting-help","title":"Getting Help","text":"<ul> <li>Check the MkDocs documentation</li> <li>Review the Material theme documentation</li> <li>Run <code>./scripts/docs.sh help</code> for command options</li> </ul>"},{"location":"setup_local_deployment/#workflow","title":"\ud83d\udcdd Workflow","text":""},{"location":"setup_local_deployment/#typical-development-workflow","title":"Typical Development Workflow","text":"<ol> <li>Make changes to your documentation files</li> <li>Test locally with <code>./scripts/docs.sh serve</code></li> <li>Build and deploy with <code>./scripts/docs.sh deploy</code></li> <li>Your docs are live at the GitHub Pages URL</li> </ol>"},{"location":"setup_local_deployment/#advantages-of-local-deployment","title":"Advantages of Local Deployment","text":"<ul> <li>\u2705 Simple and direct - No complex CI/CD setup</li> <li>\u2705 Fast deployment - Deploy when you want</li> <li>\u2705 Full control - You control when and what gets deployed</li> <li>\u2705 No environment issues - Works on your local machine</li> <li>\u2705 Easy debugging - Test everything locally first</li> </ul>"},{"location":"setup_local_deployment/#success","title":"\ud83c\udf89 Success!","text":"<p>Once deployed, your documentation will be:</p> <ul> <li>\u2705 Available at <code>https://nima-siboni.github.io/collectivecrossing/</code></li> <li>\u2705 Searchable and well-organized</li> <li>\u2705 Mobile-responsive</li> <li>\u2705 Easy to maintain and update</li> </ul> <p>Happy documenting! \ud83d\udcda\u2728</p>"},{"location":"trajectory_testing/","title":"\ud83c\udfac Trajectory Testing with VCR","text":"<p>This document explains the VCR-style trajectory testing system used to ensure consistency during refactoring of the CollectiveCrossing environment.</p>"},{"location":"trajectory_testing/#overview","title":"\ud83d\udccb Overview","text":"<p>The trajectory testing system records environment interactions (actions \u2192 observations, rewards, terminations) and replays them to verify that refactored code produces identical behavior. This prevents regressions during code changes.</p>"},{"location":"trajectory_testing/#how-it-works","title":"\u2699\ufe0f How It Works","text":""},{"location":"trajectory_testing/#vcr-video-cassette-recorder-concept","title":"VCR (Video Cassette Recorder) Concept","text":"<p>The system works like a VCR for environment interactions:</p> <ol> <li>Record Mode: Capture complete environment state at each step</li> <li>Replay Mode: Feed the same actions and verify identical outputs</li> <li>Comparison: Detect any behavioral changes during refactoring</li> </ol>"},{"location":"trajectory_testing/#key-components","title":"Key Components","text":"<ul> <li>TrajectoryVCR Class: Main recorder/replayer</li> <li>Golden Baselines: Known good trajectories from working code</li> <li>Version-Specific Trajectories: Track changes across versions</li> <li>JSON Storage: Trajectories stored as structured data files</li> </ul>"},{"location":"trajectory_testing/#directory-structure","title":"Directory Structure","text":"<pre><code>tests/fixtures/trajectories/\n\u251c\u2500\u2500 golden/                    # Golden baselines (known good)\n\u2502   \u251c\u2500\u2500 golden_basic_trajectory.json\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 current/                   # Current version trajectories\n\u2502   \u251c\u2500\u2500 test_basic_trajectory.json\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 v1.0/                      # Version-specific trajectories\n\u2502   \u2514\u2500\u2500 ...\n\u2514\u2500\u2500 v2.0/\n    \u2514\u2500\u2500 ...\n</code></pre>"},{"location":"trajectory_testing/#version-control","title":"Version Control","text":""},{"location":"trajectory_testing/#what-to-commit","title":"What to Commit","text":"<ul> <li><code>golden/</code> directory: Golden baselines should be committed to version control</li> <li>\ud83d\udccb Test files: All test files should be committed</li> </ul>"},{"location":"trajectory_testing/#what-not-to-commit","title":"What NOT to Commit","text":"<ul> <li><code>current/</code> directory: Current trajectories are temporary test artifacts</li> <li>Version-specific directories: These are generated during testing</li> </ul> <p>The <code>current/</code> directory is automatically ignored by <code>.gitignore</code>:</p> <pre><code># VCR trajectory test artifacts\ntests/fixtures/trajectories/current/\n</code></pre>"},{"location":"trajectory_testing/#golden-baseline-lifecycle","title":"Golden Baseline Lifecycle","text":"<ol> <li>Create: Golden baselines are created from known-good code</li> <li>Commit: Golden baselines are committed to version control</li> <li>Test: Tests compare current behavior against golden baselines</li> <li>Update: Golden baselines are updated when behavior intentionally changes</li> </ol>"},{"location":"trajectory_testing/#usage","title":"Usage","text":""},{"location":"trajectory_testing/#1-creating-golden-baselines","title":"1. Creating Golden Baselines","text":"<p>Golden baselines are trajectories from known good code that serve as reference points.</p> <pre><code># Create golden baseline from working code\nuv run pytest tests/collectivecrossing/envs/test_trajectory_vcr.py::test_create_golden_baseline -v\n</code></pre> <p>When to create golden baselines: - Before starting major refactoring - After fixing bugs in working code - When you have a stable, tested version</p> <p>Important: Tests now preserve existing golden baselines. They will only create new ones if they don't exist, preventing accidental overwrites.</p>"},{"location":"trajectory_testing/#2-comparing-against-golden-baselines","title":"2. Comparing Against Golden Baselines","text":"<p>Compare current code behavior against golden baselines to detect regressions.</p> <pre><code># Compare current trajectory with golden baseline\nuv run pytest tests/collectivecrossing/envs/test_trajectory_vcr.py::test_golden_baseline_comparison -v\n</code></pre> <p>What this catches: - Changes in agent behavior - Reward calculation changes - Termination condition changes - Observation space changes</p> <p>Test Behavior: This test requires the golden baseline to exist and will fail with a clear error message if it's missing.</p>"},{"location":"trajectory_testing/#3-version-specific-testing","title":"3. Version-Specific Testing","text":"<p>Track changes across different versions of your code.</p> <pre><code># Test version-specific trajectories\nuv run pytest tests/collectivecrossing/envs/test_trajectory_vcr.py::test_version_specific_trajectories -v\n</code></pre>"},{"location":"trajectory_testing/#4-running-all-tests","title":"4. Running All Tests","text":"<pre><code># Run all trajectory VCR tests\nuv run pytest tests/collectivecrossing/envs/test_trajectory_vcr.py -v\n</code></pre>"},{"location":"trajectory_testing/#creating-new-versions","title":"Creating New Versions","text":""},{"location":"trajectory_testing/#step-1-create-version-specific-vcr","title":"Step 1: Create Version-Specific VCR","text":"<pre><code>from tests.collectivecrossing.envs.test_trajectory_vcr import TrajectoryVCR\n\n# Create VCR for new version\nvcr_new = TrajectoryVCR(version=\"v2.1\")\n</code></pre>"},{"location":"trajectory_testing/#step-2-record-trajectories","title":"Step 2: Record Trajectories","text":"<pre><code># Record trajectory for new version\ntrajectory = vcr_new.record_trajectory(env, actions_sequence, \"new_feature_test\")\n</code></pre>"},{"location":"trajectory_testing/#step-3-compare-with-previous-version","title":"Step 3: Compare with Previous Version","text":"<pre><code># Compare with previous version\nvcr_old = TrajectoryVCR(version=\"v2.0\")\nvcr_old._compare_trajectories(old_trajectory, new_trajectory, \"v2.0\", \"v2.1\")\n</code></pre>"},{"location":"trajectory_testing/#creating-golden-baselines","title":"Creating Golden Baselines","text":""},{"location":"trajectory_testing/#method-1-using-test-functions","title":"Method 1: Using Test Functions","text":"<pre><code># Run the golden baseline creation test\nuv run pytest tests/collectivecrossing/envs/test_trajectory_vcr.py::test_create_golden_baseline -v\n</code></pre>"},{"location":"trajectory_testing/#method-2-manual-creation","title":"Method 2: Manual Creation","text":"<pre><code>from tests.collectivecrossing.envs.test_trajectory_vcr import TrajectoryVCR, create_test_environment, generate_deterministic_actions\n\n# Create VCR\nvcr = TrajectoryVCR()\n\n# Create environment\nenv = create_test_environment()\nobservations, _ = env.reset(seed=42)\n\n# Generate actions\nactions_sequence = generate_deterministic_actions(observations, num_steps=20)\n\n# Create golden baseline\ntrajectory = vcr.create_golden_baseline(env, actions_sequence, \"my_golden_baseline\")\n</code></pre>"},{"location":"trajectory_testing/#method-3-command-line-script","title":"Method 3: Command Line Script","text":"<pre><code># Run the manual script\nuv run python tests/collectivecrossing/envs/test_trajectory_vcr.py\n</code></pre>"},{"location":"trajectory_testing/#trajectory-data-structure","title":"Trajectory Data Structure","text":"<p>Each trajectory is stored as a JSON file with the following structure:</p> <pre><code>{\n  \"config\": {\n    \"width\": 10,\n    \"height\": 6,\n    \"division_y\": 3,\n    \"tram_door_left\": 4,\n    \"tram_door_right\": 5,\n    \"tram_length\": 8,\n    \"num_boarding_agents\": 2,\n    \"num_exiting_agents\": 1,\n    \"exiting_destination_area_y\": 0,\n    \"boarding_destination_area_y\": 5\n  },\n  \"initial_observations\": {\n    \"boarding_0\": [2, 1, 5, 3, 4, 5, ...],\n    \"boarding_1\": [7, 2, 5, 3, 4, 5, ...],\n    \"exiting_0\": [4, 4, 5, 3, 4, 5, ...]\n  },\n  \"initial_infos\": {\n    \"boarding_0\": {\"agent_type\": \"boarding\"},\n    \"boarding_1\": {\"agent_type\": \"boarding\"},\n    \"exiting_0\": {\"agent_type\": \"exiting\"}\n  },\n  \"steps\": [\n    {\n      \"step\": 0,\n      \"actions\": {\n        \"boarding_0\": 0,\n        \"boarding_1\": 2,\n        \"exiting_0\": 3\n      },\n      \"observations\": {\n        \"boarding_0\": [2, 1, 5, 3, 4, 5, ...],\n        \"boarding_1\": [7, 2, 5, 3, 4, 5, ...],\n        \"exiting_0\": [4, 4, 5, 3, 4, 5, ...]\n      },\n      \"next_observations\": {\n        \"boarding_0\": [3, 1, 5, 3, 4, 5, ...],\n        \"boarding_1\": [6, 2, 5, 3, 4, 5, ...],\n        \"exiting_0\": [4, 3, 5, 3, 4, 5, ...]\n      },\n      \"next_rewards\": {\n        \"boarding_0\": -0.3,\n        \"boarding_1\": -0.4,\n        \"exiting_0\": 0.1\n      },\n      \"next_terminated\": {\n        \"boarding_0\": false,\n        \"boarding_1\": false,\n        \"exiting_0\": false,\n        \"__all__\": false\n      },\n      \"next_truncated\": {\n        \"boarding_0\": false,\n        \"boarding_1\": false,\n        \"exiting_0\": false,\n        \"__all__\": false\n      },\n      \"next_infos\": {\n        \"boarding_0\": {\"agent_type\": \"boarding\", \"in_tram_area\": false, \"at_door\": false},\n        \"boarding_1\": {\"agent_type\": \"boarding\", \"in_tram_area\": false, \"at_door\": false},\n        \"exiting_0\": {\"agent_type\": \"exiting\", \"in_tram_area\": true, \"at_door\": false}\n      }\n    }\n  ]\n}\n</code></pre>"},{"location":"trajectory_testing/#best-practices","title":"Best Practices","text":""},{"location":"trajectory_testing/#1-when-to-create-golden-baselines","title":"1. \ud83c\udfc6 When to Create Golden Baselines","text":"<ul> <li>Before major refactoring: Create baselines from stable code</li> <li>After bug fixes: Update baselines to reflect correct behavior</li> <li>Before releases: Ensure baselines represent intended behavior</li> </ul>"},{"location":"trajectory_testing/#2-test-coverage","title":"2. \ud83c\udfaf Test Coverage","text":"<ul> <li>Multiple scenarios: Create baselines for different environment configurations</li> <li>Edge cases: Include trajectories that test boundary conditions</li> <li>Common paths: Focus on typical agent behaviors</li> </ul>"},{"location":"trajectory_testing/#3-maintenance","title":"3. \ud83d\udd27 Maintenance","text":"<ul> <li>Regular updates: Update golden baselines when behavior intentionally changes</li> <li>Version control: Commit trajectory files to track changes over time</li> <li>Documentation: Document why baselines were updated</li> </ul>"},{"location":"trajectory_testing/#4-debugging","title":"4. \ud83d\udc1b Debugging","text":"<p>When tests fail, the system provides detailed information:</p> <ul> <li>Step-by-step comparison: Shows exactly where trajectories diverge</li> <li>Agent-specific details: Identifies which agents behave differently</li> <li>State differences: Shows observation, reward, and termination differences</li> </ul>"},{"location":"trajectory_testing/#troubleshooting","title":"\ud83d\udd27 Troubleshooting","text":""},{"location":"trajectory_testing/#understanding-test-skipping","title":"Understanding Test Skipping","text":"<p>The VCR testing system is designed to skip tests when required golden baseline files are missing. This is intentional behavior to prevent false failures when baseline data isn't available.</p> <p>Why tests are skipped: - Golden baselines missing: Tests require specific golden baseline files to compare against - No comparison data: Without baselines, tests can't verify consistency - Prevents false failures: Skipping is better than failing due to missing data</p> <p>Common skipped tests: - <code>test_replay_trajectory</code>: Requires <code>test_basic_trajectory.json</code> in golden directory - <code>test_trajectory_consistency</code>: Requires <code>consistency_test.json</code> in golden directory</p> <p>How to identify what's missing:</p> <pre><code># Run tests with verbose output to see skip reasons\nuv run pytest tests/collectivecrossing/envs/test_trajectory_vcr.py -v -rs\n\n# Check what golden baselines exist\nls tests/fixtures/trajectories/golden/\n\n# Check what current trajectories exist\nls tests/fixtures/trajectories/current/\n</code></pre>"},{"location":"trajectory_testing/#common-issues","title":"\ud83d\udea8 Common Issues","text":"<ol> <li> <p>Missing Golden Baseline <code>pytest.skip: Golden baseline test_name not found. Create golden baseline first.</code> Solution: Run the golden baseline creation test first.</p> </li> <li> <p>Tests Being Skipped <code>pytest.skip: Golden cassette test_basic_trajectory not found. Create golden baseline first.    pytest.skip: Golden cassette consistency_test not found. Create golden baseline first.</code>    ** Solution**: These tests require specific golden baseline files. You can resolve this by:</p> </li> </ol> <p>Option A: Create golden baselines automatically <code>bash    # Create all required golden baselines    uv run pytest tests/collectivecrossing/envs/test_trajectory_vcr.py::test_create_golden_baseline -v</code></p> <p>Option B: Copy existing current trajectories to golden baselines <code>bash    # Copy specific missing files    cp tests/fixtures/trajectories/current/test_basic_trajectory.json tests/fixtures/trajectories/golden/    cp tests/fixtures/trajectories/current/consistency_test.json tests/fixtures/trajectories/golden/</code></p> <p>Option C: Check what golden baselines exist    ```bash    # List existing golden baselines    ls tests/fixtures/trajectories/golden/</p> <p># List current trajectories that can be copied    ls tests/fixtures/trajectories/current/    ```</p> <ol> <li> <p>\u2699\ufe0f Config Mismatch <code>pytest.fail: Config mismatch between golden and current</code> Solution: Ensure environment configuration matches between recording and replay.</p> </li> <li> <p>\ud83d\udc41\ufe0f Observation Mismatch <code>pytest.fail: Observation mismatch for agent_id at step N</code> Solution: Check for changes in environment logic that affect agent behavior.</p> </li> <li> <p>\ud83d\udd04 Golden Baseline Modified <code>git status shows modified golden baseline files</code> \ud83d\udca1 Solution: Tests now preserve golden baselines. If you see modifications, it means:</p> </li> <li>The test detected a regression (intentional behavior)</li> <li>You need to update golden baselines for intentional changes</li> <li>Restore golden baselines with <code>git restore tests/fixtures/trajectories/golden/</code></li> </ol>"},{"location":"trajectory_testing/#debugging-commands","title":"\ud83d\udee0\ufe0f Debugging Commands","text":"<pre><code># \ud83d\udccb List available golden baselines\npython -c \"from tests.collectivecrossing.envs.test_trajectory_vcr import TrajectoryVCR; vcr = TrajectoryVCR(); print('Golden:', vcr.list_golden_baselines())\"\n\n# \ud83d\udccb List current version trajectories\npython -c \"from tests.collectivecrossing.envs.test_trajectory_vcr import TrajectoryVCR; vcr = TrajectoryVCR(); print('Current:', vcr.list_version_trajectories())\"\n\n# \ud83d\udd0d Inspect trajectory file\ncat tests/fixtures/trajectories/golden/golden_basic_trajectory.json | jq '.steps[0]'\n</code></pre>"},{"location":"trajectory_testing/#integration-with-cicd","title":"\ud83d\udd04 Integration with CI/CD","text":"<p>The trajectory testing system integrates with the GitHub Actions workflow:</p> <pre><code># .github/workflows/test.yml\n- name: Run trajectory tests\n  run: |\n    uv run pytest tests/collectivecrossing/envs/test_trajectory_vcr.py -v\n</code></pre> <p>This ensures that: - \u2705 Trajectory consistency is checked on every commit - \ud83d\udea8 Regressions are caught before merging - \ud83d\udcdd Behavioral changes are documented and reviewed</p>"},{"location":"trajectory_testing/#advanced-usage","title":"\ud83d\ude80 Advanced Usage","text":""},{"location":"trajectory_testing/#custom-action-sequences","title":"\ud83c\udfaf Custom Action Sequences","text":"<pre><code>def custom_action_sequence(observations, num_steps):\n    \"\"\"Generate custom deterministic actions\"\"\"\n    actions_sequence = []\n    for step in range(num_steps):\n        actions = {}\n        for agent_id in observations.keys():\n            # Custom logic here\n            actions[agent_id] = custom_policy(observations[agent_id])\n        actions_sequence.append(actions)\n    return actions_sequence\n\n# Use custom actions\ntrajectory = vcr.record_trajectory(env, custom_action_sequence(observations, 20), \"custom_test\")\n</code></pre>"},{"location":"trajectory_testing/#multiple-environment-configurations","title":"\ud83d\udccb Multiple Environment Configurations","text":"<pre><code>def test_multiple_configs():\n    configs = [\n        {\"width\": 10, \"height\": 6, \"num_boarding_agents\": 2},\n        {\"width\": 15, \"height\": 8, \"num_boarding_agents\": 4},\n        {\"width\": 8, \"height\": 4, \"num_boarding_agents\": 1}\n    ]\n\n    for i, config in enumerate(configs):\n        env = create_test_environment_with_config(config)\n        trajectory = vcr.create_golden_baseline(env, actions, f\"config_{i}\")\n</code></pre> <p>This trajectory testing system provides robust regression testing for the CollectiveCrossing environment, ensuring that refactoring doesn't introduce behavioral changes. \ud83c\udf89</p>"},{"location":"usage/","title":"Usage Guide","text":""},{"location":"usage/#basic-usage","title":"Basic Usage","text":""},{"location":"usage/#quick-start-example","title":"Quick Start Example","text":"<pre><code>from collectivecrossing import CollectiveCrossingEnv\nfrom collectivecrossing.configs import CollectiveCrossingConfig\nfrom collectivecrossing.reward_configs import DefaultRewardConfig\nfrom collectivecrossing.terminated_configs import AllAtDestinationTerminatedConfig\nfrom collectivecrossing.truncated_configs import MaxStepsTruncatedConfig\n\n# Create configuration with configurable systems\nreward_config = DefaultRewardConfig(\n    boarding_destination_reward=15.0,\n    tram_door_reward=10.0,\n    tram_area_reward=5.0,\n    distance_penalty_factor=0.1\n)\n\nterminated_config = AllAtDestinationTerminatedConfig()\ntruncated_config = MaxStepsTruncatedConfig(max_steps=100)\n\nconfig = CollectiveCrossingConfig(\n    width=12, height=8, division_y=4,\n    tram_door_left=5, tram_door_right=6, tram_length=10,\n    num_boarding_agents=5, num_exiting_agents=3,\n    render_mode=\"rgb_array\",\n    reward_config=reward_config,\n    terminated_config=terminated_config,\n    truncated_config=truncated_config\n)\n\n# Create environment\nenv = CollectiveCrossingEnv(config=config)\n\n# Reset environment\nobservations, infos = env.reset(seed=42)\n\n# Take actions for all agents\nactions = {\n    \"boarding_0\": 0,  # Move right\n    \"boarding_1\": 1,  # Move up\n    \"boarding_2\": 2,  # Move left\n    \"boarding_3\": 3,  # Move down\n    \"boarding_4\": 4,  # Wait\n    \"exiting_0\": 0,   # Move right\n    \"exiting_1\": 1,   # Move up\n    \"exiting_2\": 2,   # Move left\n}\n\n# Step the environment\nobservations, rewards, terminated, truncated, infos = env.step(actions)\n\n# Render the environment\nrgb_array = env.render()\n</code></pre>"},{"location":"usage/#configuration-system","title":"Configuration System","text":""},{"location":"usage/#configuration-building","title":"Configuration Building","text":"<p>The project uses a type-safe configuration system with automatic validation:</p> <pre><code>from collectivecrossing.configs import CollectiveCrossingConfig\n\n# Create a configuration with automatic validation\nconfig = CollectiveCrossingConfig(\n    width=12,                    # Environment width\n    height=8,                    # Environment height\n    division_y=4,                # Y-coordinate of tram/waiting area division\n    tram_door_left=5,            # Left boundary of tram door\n    tram_door_right=6,           # Right boundary of tram door\n    tram_length=10,              # Length of the tram\n    num_boarding_agents=5,       # Number of agents trying to board\n    num_exiting_agents=3,        # Number of agents trying to exit\n    # Maximum steps are configured in truncated_config\n    exiting_destination_area_y=1,    # Y-coordinate for exit destination\n    boarding_destination_area_y=7,   # Y-coordinate for boarding destination\n    render_mode=\"rgb_array\"      # Rendering mode\n)\n</code></pre>"},{"location":"usage/#automatic-validation","title":"Automatic Validation","text":"<p>The configuration system automatically validates: - Tram parameters (door position, width, length) - Destination areas (within valid boundaries) - Environment bounds (grid dimensions) - Agent counts (reasonable limits) - Render modes (valid options)</p> <pre><code># Invalid configuration will raise descriptive errors\ntry:\n    config = CollectiveCrossingConfig(\n        width=10, tram_length=15  # Error: tram length &gt; width\n    )\nexcept ValueError as e:\n    print(f\"Configuration error: {e}\")\n</code></pre>"},{"location":"usage/#reward-configuration","title":"Reward Configuration","text":"<p>The environment supports multiple reward strategies with configurable parameters:</p>"},{"location":"usage/#default-reward-system","title":"Default Reward System","text":"<pre><code>from collectivecrossing.reward_configs import DefaultRewardConfig\n\n# Configure default reward system\nreward_config = DefaultRewardConfig(\n    boarding_destination_reward=15.0,  # Reward for reaching boarding destination\n    tram_door_reward=10.0,            # Reward for reaching tram door\n    tram_area_reward=5.0,             # Reward for being in tram area\n    distance_penalty_factor=0.1       # Distance-based penalty factor\n)\n\nconfig = CollectiveCrossingConfig(\n    # ... other parameters ...\n    reward_config=reward_config\n)\n</code></pre>"},{"location":"usage/#simple-distance-reward","title":"Simple Distance Reward","text":"<pre><code>from collectivecrossing.reward_configs import SimpleDistanceRewardConfig\n\n# Configure simple distance-based rewards\nreward_config = SimpleDistanceRewardConfig(\n    distance_penalty_factor=0.1  # Penalty based on distance to goal\n)\n\nconfig = CollectiveCrossingConfig(\n    # ... other parameters ...\n    reward_config=reward_config\n)\n</code></pre>"},{"location":"usage/#binary-reward-system","title":"Binary Reward System","text":"<pre><code>from collectivecrossing.reward_configs import BinaryRewardConfig\n\n# Configure binary rewards (goal reached or not)\nreward_config = BinaryRewardConfig(\n    goal_reward=1.0,      # Reward when goal is reached\n    no_goal_reward=0.0    # Reward when goal is not reached\n)\n\nconfig = CollectiveCrossingConfig(\n    # ... other parameters ...\n    reward_config=reward_config\n)\n</code></pre>"},{"location":"usage/#termination-configuration","title":"Termination Configuration","text":"<p>Configure when episodes should terminate:</p>"},{"location":"usage/#all-agents-at-destination","title":"All Agents at Destination","text":"<pre><code>from collectivecrossing.terminated_configs import AllAtDestinationTerminatedConfig\n\n# Episode terminates only when ALL agents reach their destinations\nterminated_config = AllAtDestinationTerminatedConfig()\n\nconfig = CollectiveCrossingConfig(\n    # ... other parameters ...\n    terminated_config=terminated_config\n)\n</code></pre>"},{"location":"usage/#individual-agent-termination","title":"Individual Agent Termination","text":"<pre><code>from collectivecrossing.terminated_configs import IndividualAtDestinationTerminatedConfig\n\n# Each agent terminates individually when reaching its destination\nterminated_config = IndividualAtDestinationTerminatedConfig()\n\nconfig = CollectiveCrossingConfig(\n    # ... other parameters ...\n    terminated_config=terminated_config\n)\n</code></pre>"},{"location":"usage/#custom-termination","title":"Custom Termination","text":"<pre><code>from collectivecrossing.terminated_configs import CustomTerminatedConfig\n\n# Custom termination with specific parameters\nterminated_config = CustomTerminatedConfig(\n    terminated_function=\"custom_termination\",\n    max_steps_per_agent=1000,\n    require_all_completion=False,\n    timeout_penalty=True\n)\n\nconfig = CollectiveCrossingConfig(\n    # ... other parameters ...\n    terminated_config=terminated_config\n)\n</code></pre>"},{"location":"usage/#truncation-configuration","title":"Truncation Configuration","text":"<p>Configure episode truncation policies:</p>"},{"location":"usage/#max-steps-truncation","title":"Max Steps Truncation","text":"<pre><code>from collectivecrossing.truncated_configs import MaxStepsTruncatedConfig\n\n# Episode truncates after maximum steps\ntruncated_config = MaxStepsTruncatedConfig(\n    max_steps=1000  # Maximum steps before truncation\n)\n\nconfig = CollectiveCrossingConfig(\n    # ... other parameters ...\n    truncated_config=truncated_config\n)\n</code></pre>"},{"location":"usage/#custom-truncation","title":"Custom Truncation","text":"<pre><code>from collectivecrossing.truncated_configs import CustomTruncatedConfig\n\n# Custom truncation with advanced parameters\ntruncated_config = CustomTruncatedConfig(\n    truncated_function=\"custom_truncation\",\n    max_steps=1000,\n    early_truncation_threshold=0.8,  # Truncate early if 80% complete\n    require_all_agents_active=False\n)\n\nconfig = CollectiveCrossingConfig(\n    # ... other parameters ...\n    truncated_config=truncated_config\n)\n</code></pre>"},{"location":"usage/#complete-configuration-example","title":"Complete Configuration Example","text":"<pre><code>from collectivecrossing import CollectiveCrossingEnv\nfrom collectivecrossing.configs import CollectiveCrossingConfig\nfrom collectivecrossing.reward_configs import DefaultRewardConfig\nfrom collectivecrossing.terminated_configs import AllAtDestinationTerminatedConfig\nfrom collectivecrossing.truncated_configs import MaxStepsTruncatedConfig\n\n# Create comprehensive configuration\nreward_config = DefaultRewardConfig(\n    boarding_destination_reward=20.0,\n    tram_door_reward=15.0,\n    tram_area_reward=8.0,\n    distance_penalty_factor=0.05\n)\n\nterminated_config = AllAtDestinationTerminatedConfig()\ntruncated_config = MaxStepsTruncatedConfig(max_steps=500)\n\nconfig = CollectiveCrossingConfig(\n    width=15, height=10, division_y=5,\n    tram_door_left=6, tram_door_right=8, tram_length=12,\n    num_boarding_agents=6, num_exiting_agents=4,\n    exiting_destination_area_y=1, boarding_destination_area_y=8,\n    render_mode=\"rgb_array\",\n    reward_config=reward_config,\n    terminated_config=terminated_config,\n    truncated_config=truncated_config\n)\n\n# Create and use environment\nenv = CollectiveCrossingEnv(config=config)\nobservations, infos = env.reset(seed=42)\n</code></pre>"},{"location":"usage/#visualization","title":"Visualization","text":""},{"location":"usage/#rgb-rendering","title":"RGB Rendering","text":"<pre><code>import matplotlib.pyplot as plt\n\n# Create environment with RGB rendering\nconfig = CollectiveCrossingConfig(\n    width=12, height=8, division_y=4,\n    tram_door_left=5, tram_door_right=6, tram_length=10,\n    num_boarding_agents=5, num_exiting_agents=3,\n    render_mode=\"rgb_array\"\n)\nenv = CollectiveCrossingEnv(config=config)\n\n# Reset and render\nobservations, infos = env.reset(seed=42)\nrgb_array = env.render()\n\n# Display\nplt.figure(figsize=(12, 8))\nplt.imshow(rgb_array)\nplt.axis('off')\nplt.title('Collective Crossing Environment')\nplt.show()\n</code></pre>"},{"location":"usage/#ascii-rendering","title":"ASCII Rendering","text":"<pre><code># Create environment with ASCII rendering\nconfig = CollectiveCrossingConfig(\n    width=12, height=8, division_y=4,\n    tram_door_left=5, tram_door_right=6, tram_length=10,\n    num_boarding_agents=5, num_exiting_agents=3,\n    render_mode=\"ansi\"\n)\nenv = CollectiveCrossingEnv(config=config)\n\n# Reset and render\nobservations, infos = env.reset(seed=42)\nascii_frame = env.render()\n\n# Print ASCII representation\nprint(ascii_frame)\n</code></pre>"},{"location":"usage/#environment-extensions","title":"Environment Extensions","text":"<p>The environment supports various extensions through its configuration system:</p>"},{"location":"usage/#custom-reward-functions","title":"Custom Reward Functions","text":"<pre><code>from collectivecrossing.reward_configs import CustomRewardConfig\n\n# Create custom reward configuration\nreward_config = CustomRewardConfig(\n    reward_function=\"custom\",\n    # Add your custom parameters here\n)\n\nconfig = CollectiveCrossingConfig(\n    # ... other parameters ...\n    reward_config=reward_config\n)\n</code></pre>"},{"location":"usage/#custom-termination-functions","title":"Custom Termination Functions","text":"<pre><code>from collectivecrossing.terminated_configs import CustomTerminatedConfig\n\n# Create custom termination configuration\nterminated_config = CustomTerminatedConfig(\n    terminated_function=\"custom\",\n    max_steps_per_agent=1000,\n    require_all_completion=False\n)\n\nconfig = CollectiveCrossingConfig(\n    # ... other parameters ...\n    terminated_config=terminated_config\n)\n</code></pre>"},{"location":"usage/#custom-truncation-functions","title":"Custom Truncation Functions","text":"<pre><code>from collectivecrossing.truncated_configs import CustomTruncatedConfig\n\n# Create custom truncation configuration\ntruncated_config = CustomTruncatedConfig(\n    truncated_function=\"custom\",\n    max_steps=1000,\n    early_truncation_threshold=0.8\n)\n\nconfig = CollectiveCrossingConfig(\n    # ... other parameters ...\n    truncated_config=truncated_config\n)\n</code></pre>"},{"location":"usage/#action-space","title":"Action Space","text":"<p>The environment supports the following actions:</p> <ul> <li><code>0</code>: Move right</li> <li><code>1</code>: Move up</li> <li><code>2</code>: Move left</li> <li><code>3</code>: Move down</li> <li><code>4</code>: Wait (no movement)</li> </ul>"},{"location":"usage/#observation-space","title":"Observation Space","text":"<p>The environment provides configurable observation functions that can be customized for different use cases.</p>"},{"location":"usage/#default-observation-function","title":"Default Observation Function","text":"<p>The default observation function provides: - Agent's own position (x, y coordinates) - Tram door information (door center x, division line y, door boundaries) - Other agents' positions (positions of all other agents in the environment)</p>"},{"location":"usage/#observation-structure","title":"Observation Structure","text":"<pre><code>from collectivecrossing.observation_configs import DefaultObservationConfig\n\n# Create observation configuration\nobservation_config = DefaultObservationConfig()\n\nconfig = CollectiveCrossingConfig(\n    # ... other parameters ...\n    observation_config=observation_config\n)\n</code></pre>"},{"location":"usage/#custom-observation-functions","title":"Custom Observation Functions","text":"<p>You can create custom observation functions by extending the <code>ObservationFunction</code> base class:</p> <pre><code>from collectivecrossing.observation_configs import ObservationConfig\nfrom collectivecrossing.observations import ObservationFunction\n\nclass CustomObservationConfig(ObservationConfig):\n    observation_function: str = \"custom\"\n\n    def get_observation_function_name(self) -&gt; str:\n        return \"custom\"\n\nclass CustomObservationFunction(ObservationFunction):\n    def get_agent_observation(self, agent_id: str, env: \"CollectiveCrossingEnv\") -&gt; np.ndarray:\n        # Implement your custom observation logic here\n        # Return observation as numpy array\n        pass\n</code></pre>"},{"location":"usage/#observation-space-properties","title":"Observation Space Properties","text":"<pre><code># Get observation space for all agents\nobservation_spaces = env.observation_spaces\n\n# Get observation space for a specific agent\nagent_obs_space = env.get_observation_space(\"boarding_0\")\n</code></pre>"},{"location":"usage/#reward-system","title":"Reward System","text":"<p>Rewards are based on: - Distance to goal - Successful goal completion - Collision penalties - Time penalties - Configurable reward strategies</p>"},{"location":"usage/#multi-agent-environment","title":"Multi-Agent Environment","text":"<p>The environment follows the Ray RLlib MultiAgentEnv API:</p> <pre><code># Get action space for all agents\naction_spaces = env.action_spaces\n\n# Get observation space for all agents\nobservation_spaces = env.observation_spaces\n\n# Get agent IDs\nagent_ids = list(env.agents)\n</code></pre>"},{"location":"usage/#examples","title":"Examples","text":"<p>Check the <code>examples/</code> directory for complete usage examples:</p> <pre><code># Run example\nuv run python examples/collectivecrossing_example.py\n</code></pre>"}]}